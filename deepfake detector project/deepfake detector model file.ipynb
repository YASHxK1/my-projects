{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install numpy tensorflow matplotlib seaborn scikit-learn gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:21:09.221340Z",
     "iopub.status.busy": "2025-02-20T22:21:09.220985Z",
     "iopub.status.idle": "2025-02-20T22:21:31.351276Z",
     "shell.execute_reply": "2025-02-20T22:21:31.350368Z",
     "shell.execute_reply.started": "2025-02-20T22:21:09.221297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:21:31.354236Z",
     "iopub.status.busy": "2025-02-20T22:21:31.353390Z",
     "iopub.status.idle": "2025-02-20T22:23:04.911759Z",
     "shell.execute_reply": "2025-02-20T22:23:04.910562Z",
     "shell.execute_reply.started": "2025-02-20T22:21:31.354201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "fake_dir = \"D:\\codes\\ML\\deepfake detector\\Data\\Fake\"\n",
    "real_dir = \"D:\\codes\\ML\\deepfake detector\\Data\\Real\"\n",
    "\n",
    "# Load images\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = image.load_img(os.path.join(folder, filename), target_size=(128, 128))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img / 255.0  # Normalize the image\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load fake and real images\n",
    "fake_images, fake_labels = load_images_from_folder(fake_dir, 0)\n",
    "real_images, real_labels = load_images_from_folder(real_dir, 1)\n",
    "\n",
    "# Combine the data\n",
    "X = np.array(fake_images + real_images)\n",
    "y = np.array(fake_labels + real_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:23:04.913597Z",
     "iopub.status.busy": "2025-02-20T22:23:04.913274Z",
     "iopub.status.idle": "2025-02-20T22:29:12.884344Z",
     "shell.execute_reply": "2025-02-20T22:29:12.882788Z",
     "shell.execute_reply.started": "2025-02-20T22:23:04.913568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:29:12.886806Z",
     "iopub.status.busy": "2025-02-20T22:29:12.886365Z",
     "iopub.status.idle": "2025-02-20T22:29:46.291628Z",
     "shell.execute_reply": "2025-02-20T22:29:46.290462Z",
     "shell.execute_reply.started": "2025-02-20T22:29:12.886731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:29:59.038495Z",
     "iopub.status.busy": "2025-02-20T22:29:59.038089Z",
     "iopub.status.idle": "2025-02-20T22:29:59.044430Z",
     "shell.execute_reply": "2025-02-20T22:29:59.043055Z",
     "shell.execute_reply.started": "2025-02-20T22:29:59.038458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to predict if an image is fake or real\n",
    "def predict_image(img):\n",
    "    img = image.load_img(img, target_size=(128, 128))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    prediction = model.predict(img)\n",
    "    if prediction < 0.5:\n",
    "        return \"Fake\"\n",
    "    else:\n",
    "        return \"Real\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:30:03.517763Z",
     "iopub.status.busy": "2025-02-20T22:30:03.517217Z",
     "iopub.status.idle": "2025-02-20T22:30:03.637012Z",
     "shell.execute_reply": "2025-02-20T22:30:03.635834Z",
     "shell.execute_reply.started": "2025-02-20T22:30:03.517724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save('D:\\codes\\ML\\deepfake detector\\MODELdeepfakedetector.h5')  # Saves the model in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T22:38:06.872390Z",
     "iopub.status.busy": "2025-02-20T22:38:06.871941Z",
     "iopub.status.idle": "2025-02-20T22:38:07.255435Z",
     "shell.execute_reply": "2025-02-20T22:38:07.254536Z",
     "shell.execute_reply.started": "2025-02-20T22:38:06.872355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('D:\\codes\\ML\\deepfake detector\\MODELdeepfakedetector.h5')\n",
    "\n",
    "\n",
    "# Function to predict if an image is fake or real\n",
    "def predict_image(image_path):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(128, 128))  # Resize to match model input size\n",
    "    img = image.img_to_array(img)\n",
    "    img = img / 255.0  # Normalize the image\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(img)\n",
    "    if prediction < 0.5:\n",
    "        return \"Fake\"\n",
    "    else:\n",
    "        return \"Real\"\n",
    "\n",
    "# Path to the image you want to test\n",
    "image_path = \"C:\\Users\\DELL\\Downloads\\Dataset\\Validation\\Fake\\fake_9951.jpg\"\n",
    "\n",
    "# Get the prediction\n",
    "result = predict_image(image_path)\n",
    "print(f\"The image is predicted to be: {result}\")\n",
    "##\n",
    "##\n",
    "# Path to the image you want to test\n",
    "image_path = \"C:\\Users\\DELL\\Downloads\\Dataset\\Validation\\Real\\real_0.jpg\"\n",
    "\n",
    "# Get the prediction\n",
    "result = predict_image(image_path)\n",
    "print(f\"The image is predicted to be: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1909705,
     "sourceId": 3134515,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6709065,
     "sourceId": 10808134,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
